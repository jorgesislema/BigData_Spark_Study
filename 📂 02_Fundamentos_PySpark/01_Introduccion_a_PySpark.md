# ğŸ IntroducciÃ³n a PySpark

## ğŸ”¥ Â¿QuÃ© es PySpark?
PySpark es la API de Python para **Apache Spark**, un motor de procesamiento de datos distribuido diseÃ±ado para manejar grandes volÃºmenes de datos. Permite realizar anÃ¡lisis de datos, procesamiento ETL y machine learning de manera escalable y eficiente.

---

## ğŸ“Œ Â¿Por quÃ© usar PySpark?
PySpark es ideal para trabajar con grandes volÃºmenes de datos porque:
- âœ… **Escalabilidad**: Puede procesar datos en clÃºsteres distribuidos.
- âœ… **Velocidad**: Usa procesamiento en memoria, reduciendo el acceso a disco.
- âœ… **Compatibilidad**: Funciona con Hadoop, HDFS, Amazon S3 y otras tecnologÃ­as de Big Data.
- âœ… **Flexibilidad**: Soporta SQL, machine learning y procesamiento en tiempo real.

---

## ğŸ› ï¸ InstalaciÃ³n de PySpark
Para instalar PySpark en tu mÃ¡quina local, ejecuta:
```bash
pip install pyspark
```
Si usas Google Colab, primero instala Java y luego PySpark:
```python
!apt-get install openjdk-8-jdk-headless -qq > /dev/null
!pip install pyspark
```

Para verificar la instalaciÃ³n:
```python
import pyspark
print(pyspark.__version__)
```
Si ves una versiÃ³n impresa en pantalla, la instalaciÃ³n fue exitosa.

---

## âš™ï¸ CreaciÃ³n de una SesiÃ³n en PySpark
Para comenzar a trabajar con PySpark, es necesario crear una sesiÃ³n de Spark:
```python
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("EjemploPySpark").getOrCreate()
print("SesiÃ³n de Spark creada exitosamente")
```

---

## ğŸ“Š CreaciÃ³n de un DataFrame en PySpark
Un **DataFrame** en PySpark es similar a un DataFrame de Pandas, pero distribuido en mÃºltiples nodos para un mejor rendimiento.

Ejemplo:
```python
data = [("Alice", 25), ("Bob", 30), ("Charlie", 35)]
df = spark.createDataFrame(data, ["Nombre", "Edad"])
df.show()
```
Salida esperada:
```
+-------+----+
| Nombre|Edad|
+-------+----+
|  Alice|  25|
|    Bob|  30|
|Charlie|  35|
+-------+----+
```

---

## ğŸ” Operaciones BÃ¡sicas en PySpark
### 1ï¸âƒ£ Seleccionar columnas
```python
df.select("Nombre").show()
```

### 2ï¸âƒ£ Filtrar datos
```python
df.filter(df["Edad"] > 25).show()
```

### 3ï¸âƒ£ Ordenar datos
```python
df.orderBy("Edad", ascending=False).show()
```

---

## ğŸ¯ ConclusiÃ³n
PySpark permite trabajar con grandes volÃºmenes de datos de forma eficiente y escalable. Con su integraciÃ³n con Hadoop, HDFS y otras herramientas de Big Data, se convierte en una opciÃ³n poderosa para anÃ¡lisis de datos y machine learning. ğŸš€

