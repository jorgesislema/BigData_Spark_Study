# â˜ï¸ Configurar Apache Spark en AWS

## ğŸ”¥ IntroducciÃ³n
Apache Spark es una herramienta poderosa para el procesamiento de datos a gran escala. En **AWS (Amazon Web Services)**, podemos configurar Spark en EC2 o utilizar **Amazon EMR (Elastic MapReduce)**, que ofrece una soluciÃ³n optimizada para el anÃ¡lisis de datos en clÃºsteres.

---

## ğŸ“Œ Requisitos Previos
Antes de configurar Spark en AWS, necesitas:
- âœ… Una cuenta en AWS ([https://aws.amazon.com/](https://aws.amazon.com/)).
- âœ… Conocimientos bÃ¡sicos de AWS EC2 y EMR.
- âœ… Tener configurado AWS CLI en tu mÃ¡quina local.
- âœ… Un par de claves SSH para acceder a las instancias EC2.

---

## ğŸ› ï¸ OpciÃ³n 1: Instalar Spark en una instancia EC2

### ğŸ”¹ Paso 1: Crear una instancia EC2
1. Inicia sesiÃ³n en **AWS Console**.
2. DirÃ­gete a **EC2 > Instancias** y haz clic en "**Launch Instance**".
3. Selecciona una AMI (Amazon Machine Image), como `Ubuntu 20.04` o `Amazon Linux 2`.
4. Escoge el tipo de instancia (**t2.medium** o superior para mejor rendimiento).
5. Configura el almacenamiento y la seguridad (puerto 22 abierto para SSH).
6. Genera o usa una clave SSH existente y lanza la instancia.

### ğŸ”¹ Paso 2: Conectar a la instancia y actualizar paquetes
ConÃ©ctate a la instancia desde tu terminal:
```bash
ssh -i "tu-clave.pem" ubuntu@tu-ip-publica
```
Luego, actualiza los paquetes del sistema:
```bash
sudo apt update && sudo apt upgrade -y
```

### ğŸ”¹ Paso 3: Instalar Java y Apache Spark
```bash
sudo apt install openjdk-8-jdk -y
wget https://downloads.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz
tar -xvzf spark-3.2.1-bin-hadoop3.2.tgz
mv spark-3.2.1-bin-hadoop3.2 spark
```

### ğŸ”¹ Paso 4: Configurar Variables de Entorno
```bash
echo 'export SPARK_HOME=~/spark' >> ~/.bashrc
echo 'export PATH=$SPARK_HOME/bin:$PATH' >> ~/.bashrc
echo 'export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64' >> ~/.bashrc
source ~/.bashrc
```

### ğŸ”¹ Paso 5: Verificar instalaciÃ³n de Spark
```bash
spark-shell
```
Si la consola de Spark inicia correctamente, la instalaciÃ³n fue exitosa.

---

## ğŸ† OpciÃ³n 2: Configurar Apache Spark en Amazon EMR

Si no quieres configurar manualmente un clÃºster EC2, **Amazon EMR** permite crear un clÃºster con Apache Spark preconfigurado.

### ğŸ”¹ Paso 1: Crear un clÃºster EMR
1. Inicia sesiÃ³n en **AWS Console**.
2. Ve a **Amazon EMR > Create Cluster**.
3. Selecciona el modo **Cluster estÃ¡ndar**.
4. En la secciÃ³n **Software Configuration**, elige **Apache Spark**.
5. Configura el tamaÃ±o del clÃºster (mÃ­nimo `m5.xlarge` para rendimiento Ã³ptimo).
6. Configura las claves SSH y reglas de acceso.
7. Lanza el clÃºster y espera a que el estado sea **Waiting**.

### ğŸ”¹ Paso 2: Conectar y ejecutar Spark en EMR
ConÃ©ctate a la instancia **Master Node** con SSH:
```bash
ssh -i "tu-clave.pem" hadoop@tu-ip-master
```
Para ejecutar Spark desde EMR, usa:
```bash
spark-shell
```
Si deseas trabajar con PySpark:
```bash
pyspark
```

---

## ğŸ¯ ConclusiÃ³n
Dependiendo de tu caso de uso, puedes instalar Spark manualmente en **EC2** o usar **Amazon EMR** para un despliegue mÃ¡s sencillo. EMR es recomendable para proyectos grandes con integraciÃ³n en el ecosistema de AWS. ğŸš€

