# âš™ï¸ Tuning de ParÃ¡metros en Apache Spark

## ğŸ”¥ IntroducciÃ³n
El ajuste de parÃ¡metros (**tuning**) en Apache Spark es fundamental para optimizar el rendimiento de las aplicaciones de Big Data. Configurar correctamente la memoria, el paralelismo y los recursos asignados puede reducir tiempos de ejecuciÃ³n y mejorar la eficiencia del clÃºster.

---

## ğŸ“Œ Principales ParÃ¡metros de ConfiguraciÃ³n
Los parÃ¡metros clave en Spark se dividen en tres categorÃ­as:
1. **Memoria y gestiÃ³n de recursos**
2. **OptimizaciÃ³n de ejecuciÃ³n**
3. **ConfiguraciÃ³n de shuffle y particiones**

---

## ğŸ› ï¸ ConfiguraciÃ³n de Memoria y Recursos
### ğŸ”¹ Configurar Memoria para el Driver y los Ejecutores
```python
spark.conf.set("spark.driver.memory", "4g")
spark.conf.set("spark.executor.memory", "8g")
```
| ParÃ¡metro | DescripciÃ³n |
|-----------|------------|
| `spark.driver.memory` | Cantidad de memoria asignada al Driver. |
| `spark.executor.memory` | Memoria para cada ejecutor en el clÃºster. |

âœ… **RecomendaciÃ³n**: Ajustar estos valores segÃºn la capacidad del clÃºster.

### ğŸ”¹ Configurar NÃºmero de NÃºcleos
```python
spark.conf.set("spark.executor.cores", "4")
```
| ParÃ¡metro | DescripciÃ³n |
|-----------|------------|
| `spark.executor.cores` | NÃºmero de nÃºcleos por ejecutor. |
| `spark.task.cpus` | NÃºcleos requeridos por tarea individual. |

âœ… **RecomendaciÃ³n**: Asignar un nÃºmero adecuado de nÃºcleos para balancear la carga de trabajo.

---

## ğŸ”„ OptimizaciÃ³n de EjecuciÃ³n
### ğŸ”¹ Configurar Paralelismo
```python
spark.conf.set("spark.default.parallelism", 200)
```
| ParÃ¡metro | DescripciÃ³n |
|-----------|------------|
| `spark.default.parallelism` | NÃºmero de tareas paralelas en RDDs. |
| `spark.sql.shuffle.partitions` | NÃºmero de particiones en operaciones de *shuffle*. |

âœ… **RecomendaciÃ³n**:
- **Para RDDs**: `spark.default.parallelism = 2 x nÃºcleos totales`
- **Para DataFrames**: `spark.sql.shuffle.partitions = 200` (ajustar segÃºn tamaÃ±o de datos)

---

## ğŸ”€ OptimizaciÃ³n de Shuffle y Joins
### ğŸ”¹ Ajustar el NÃºmero de Particiones en Shuffle
```python
spark.conf.set("spark.sql.shuffle.partitions", 200)
```
âœ… **Beneficio**: Evita cuellos de botella en operaciones como `groupBy()` y `join()`.

### ğŸ”¹ Habilitar Broadcast Join
```python
spark.conf.set("spark.sql.autoBroadcastJoinThreshold", 100 * 1024 * 1024)  # 100 MB
```
âœ… **Beneficio**: Mejora la eficiencia en **joins** cuando una tabla es pequeÃ±a.

---

## ğŸï¸ ComparaciÃ³n de ParÃ¡metros Clave
| CategorÃ­a | ParÃ¡metro | Efecto |
|-----------|----------|--------|
| **Memoria** | `spark.executor.memory` | Asigna memoria a los ejecutores |
| **Paralelismo** | `spark.default.parallelism` | Define la cantidad de tareas concurrentes |
| **Shuffle** | `spark.sql.shuffle.partitions` | Ajusta la eficiencia en operaciones de shuffle |
| **Joins** | `spark.sql.autoBroadcastJoinThreshold` | Optimiza *joins* con tablas pequeÃ±as |

---

## ğŸ¯ ConclusiÃ³n
Ajustar los parÃ¡metros en Apache Spark es clave para mejorar el rendimiento. Configurar correctamente **la memoria, el paralelismo y la optimizaciÃ³n de shuffle** puede reducir significativamente los tiempos de ejecuciÃ³n y mejorar la eficiencia del clÃºster. ğŸš€

