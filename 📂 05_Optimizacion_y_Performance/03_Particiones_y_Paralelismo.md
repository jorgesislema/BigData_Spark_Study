# âš¡ Particiones y Paralelismo en Apache Spark

## ğŸ”¥ IntroducciÃ³n
Apache Spark es un motor de procesamiento distribuido que divide los datos en **particiones** para ejecutar operaciones en paralelo. La gestiÃ³n eficiente de particiones y paralelismo es clave para optimizar el rendimiento y evitar problemas de sobrecarga en la memoria o ineficiencia en la distribuciÃ³n de tareas.

---

## ğŸ“Œ Â¿QuÃ© es una ParticiÃ³n en Spark?
Una **particiÃ³n** es la unidad mÃ­nima de datos procesada por un **ejecutor** dentro de un clÃºster de Spark. Spark divide automÃ¡ticamente los datos en particiones cuando se leen desde una fuente de datos como HDFS, S3 o bases de datos.

| CaracterÃ­stica | DescripciÃ³n |
|--------------|-------------|
| **TamaÃ±o de particiÃ³n** | Generalmente 128 MB por particiÃ³n en HDFS |
| **NÃºmero predeterminado** | Spark elige automÃ¡ticamente el nÃºmero de particiones |
| **Reparticionado** | Se puede ajustar manualmente usando `repartition()` y `coalesce()` |

---

## ğŸ› ï¸ Controlando el NÃºmero de Particiones
### ğŸ”¹ Ver nÃºmero de particiones actuales
```python
rdd = spark.sparkContext.parallelize(range(100), 10)  # Crea un RDD con 10 particiones
print(rdd.getNumPartitions())
```
### ğŸ”¹ Cambiar el nÃºmero de particiones
#### ğŸï¸ `repartition(n)` (Aumenta o reduce particiones con shuffle)
```python
df = df.repartition(10)  # Redistribuye los datos en 10 particiones (genera shuffle)
```

#### ğŸš€ `coalesce(n)` (Reduce particiones sin shuffle)
```python
df = df.coalesce(5)  # Reduce las particiones a 5 sin mover excesivos datos
```

âœ… **Regla general:**
- Usa `repartition(n)` si necesitas **aumentar** o cambiar la distribuciÃ³n de datos.
- Usa `coalesce(n)` para **reducir** particiones de manera eficiente.

---

## âš™ï¸ Paralelismo en Spark
El **paralelismo** en Spark se basa en el nÃºmero de **particiones** y el nÃºmero de **nÃºcleos disponibles** en el clÃºster. Spark ejecuta una tarea por cada particiÃ³n en cada nÃºcleo disponible.

### ğŸ”¹ Configurar el Nivel de Paralelismo
Podemos ajustar el nÃºmero de tareas paralelas con:
```python
spark.conf.set("spark.default.parallelism", 200)
```

âœ… **RecomendaciÃ³n:**
- **Para RDDs:** `spark.default.parallelism = 2 x nÃºmero de nÃºcleos`
- **Para DataFrames:** `spark.sql.shuffle.partitions = 200` (valor por defecto)

---

## ğŸï¸ ComparaciÃ³n entre `repartition()` y `coalesce()`
| MÃ©todo | Uso | Genera Shuffle? |
|--------|-----|---------------|
| `repartition(n)` | Redistribuye los datos en *n* particiones | âœ… SÃ­ |
| `coalesce(n)` | Reduce el nÃºmero de particiones sin grandes movimientos de datos | âŒ No |

---

## ğŸ¯ ConclusiÃ³n
Optimizar las particiones y el paralelismo en Spark permite distribuir la carga de trabajo de manera eficiente y reducir el tiempo de ejecuciÃ³n de las tareas. Aplicar `repartition()` y `coalesce()` correctamente puede mejorar el rendimiento en clÃºsteres grandes. ğŸš€

