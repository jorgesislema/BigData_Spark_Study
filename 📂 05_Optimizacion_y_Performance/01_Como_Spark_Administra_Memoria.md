# üß† ¬øC√≥mo Apache Spark Administra la Memoria?

## üî• Introducci√≥n
Apache Spark utiliza un modelo de administraci√≥n de memoria eficiente para manejar grandes vol√∫menes de datos en entornos distribuidos. Comprender su gesti√≥n de memoria es clave para optimizar el rendimiento y evitar problemas como *OutOfMemoryError*.

---

## üìå Componentes de la Memoria en Spark
La memoria en Spark se divide en dos grandes √°reas:
1. **Memoria del Driver**: Maneja la ejecuci√≥n del programa y la interacci√≥n con los ejecutores.
2. **Memoria de los Ejecutores (Executors)**: Se usa para procesar datos y realizar c√°lculos en paralelo.

Cada **Executor** divide su memoria en:
| √Årea | Descripci√≥n |
|------|------------|
| **Storage Memory** | Almacena datos en cach√© (RDDs, DataFrames). |
| **Execution Memory** | Se usa para operaciones como `shuffle`, `sort`, `aggregation`. |
| **User Memory** | Espacio disponible para el c√≥digo del usuario. |
| **Reserved Memory** | Peque√±a parte reservada para Spark internamente. |

---

## üõ†Ô∏è Configuraci√≥n de Memoria en Spark
La memoria de Spark se configura con par√°metros clave en `spark-defaults.conf` o en la creaci√≥n de una sesi√≥n:
```python
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("AdministracionMemoria") \
    .config("spark.executor.memory", "4g") \
    .config("spark.driver.memory", "2g") \
    .config("spark.memory.fraction", "0.75") \
    .getOrCreate()
```

| Par√°metro | Descripci√≥n |
|-----------|------------|
| `spark.executor.memory` | Memoria asignada a cada ejecutor. |
| `spark.driver.memory` | Memoria para el proceso principal (driver). |
| `spark.memory.fraction` | Porcentaje de memoria para Storage y Execution. |

---

## ‚ö° Optimizaci√≥n del Uso de Memoria
### üîπ 1. **Persistencia y Cach√©**
Usar `cache()` y `persist()` reduce la carga en memoria al reutilizar datos en m√∫ltiples operaciones.
```python
df = spark.read.parquet("/ruta/datos.parquet").cache()
df.count()  # Activa el cache
```

### üîπ 2. **Evitar `collect()` en Grandes Vol√∫menes de Datos**
`collect()` trae todos los datos al driver, lo que puede causar falta de memoria.
```python
# ‚ö†Ô∏è Puede agotar memoria en grandes datasets
data = df.collect()
```
‚úÖ En su lugar, usar `take()` o `show()`.
```python
df.take(10)  # Devuelve solo 10 filas
```

### üîπ 3. **Optimizar el N√∫mero de Particiones**
Ajustar las particiones ayuda a mejorar el balance de carga.
```python
df = df.repartition(10)  # Reduce n√∫mero de particiones
```

---

## üéØ Conclusi√≥n
La correcta administraci√≥n de memoria en Apache Spark es fundamental para un rendimiento eficiente. Configurar par√°metros adecuados y seguir buenas pr√°cticas como *cachear datos*, *evitar collect()* y *ajustar particiones* puede mejorar significativamente la ejecuci√≥n de los procesos. üöÄ

