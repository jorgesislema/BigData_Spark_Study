# ğŸ”¥ Comandos Ocultos en Apache Spark

## ğŸ”¥ IntroducciÃ³n
Apache Spark tiene **comandos ocultos y funciones avanzadas** que pueden mejorar la eficiencia del desarrollo y la depuraciÃ³n de cÃ³digo. Estos comandos son Ãºtiles para **optimizaciÃ³n, anÃ¡lisis de ejecuciÃ³n y depuraciÃ³n en clÃºsteres distribuidos**.

---

## ğŸ“Œ Comandos para DepuraciÃ³n y OptimizaciÃ³n

### 1ï¸âƒ£ **Mostrar Configuraciones de Spark en Tiempo de EjecuciÃ³n**
```python
print(spark.conf.get("spark.sql.shuffle.partitions"))
print(spark.conf.get("spark.executor.memory"))
```
âœ… **Beneficio:** Verifica parÃ¡metros sin acceder a archivos de configuraciÃ³n.

### 2ï¸âƒ£ **Ver el Plan de EjecuciÃ³n en Formato Completo**
```python
df.explain("extended")
```
âœ… **Beneficio:** Muestra el anÃ¡lisis lÃ³gico y fÃ­sico de la consulta.

### 3ï¸âƒ£ **Habilitar `Adaptive Query Execution (AQE)`**
```python
spark.conf.set("spark.sql.adaptive.enabled", "true")
```
âœ… **Beneficio:** Optimiza la ejecuciÃ³n de consultas en tiempo real.

---

## ğŸš€ Comandos Avanzados de DataFrames

### 4ï¸âƒ£ **Ver los 5 DataFrames mÃ¡s grandes en Memoria**
```python
spark.catalog.listTables()
```
âœ… **Beneficio:** Muestra quÃ© DataFrames estÃ¡n almacenados en cachÃ©.

### 5ï¸âƒ£ **Borrar CachÃ© de un DataFrame**
```python
spark.catalog.clearCache()
```
âœ… **Beneficio:** Libera memoria eliminando datos en cachÃ©.

### 6ï¸âƒ£ **Forzar Garbage Collection**
```python
import gc
gc.collect()
```
âœ… **Beneficio:** Reduce el uso de memoria liberando recursos innecesarios.

---

## ğŸ”„ Comandos para RDDs

### 7ï¸âƒ£ **Ver Particiones de un RDD**
```python
rdd.getNumPartitions()
```
âœ… **Beneficio:** Verifica la distribuciÃ³n de datos en el clÃºster.

### 8ï¸âƒ£ **Cambiar el NÃºmero de Particiones sin Shuffle**
```python
rdd.coalesce(5)
```
âœ… **Beneficio:** Reduce el nÃºmero de particiones sin generar trÃ¡fico de red.

---

## ğŸï¸ Comandos para OptimizaciÃ³n de Joins

### 9ï¸âƒ£ **Forzar `Broadcast Join` en una Tabla PequeÃ±a**
```python
from pyspark.sql.functions import broadcast

df1.join(broadcast(df2), "id").show()
```
âœ… **Beneficio:** Evita operaciones de shuffle en joins con tablas pequeÃ±as.

### ğŸ”Ÿ **Ver el Estado de las Tareas en Tiempo Real**
```python
spark.sparkContext.statusTracker.getExecutorInfos()
```
âœ… **Beneficio:** Monitorea el estado de los ejecutores en ejecuciÃ³n.

---

## ğŸ¯ ConclusiÃ³n
Estos **comandos ocultos y avanzados** pueden mejorar la eficiencia del desarrollo, depuraciÃ³n y optimizaciÃ³n de cÃ³digo en Apache Spark. Usarlos correctamente permite mejorar el rendimiento y la escalabilidad del procesamiento de datos. ğŸš€

