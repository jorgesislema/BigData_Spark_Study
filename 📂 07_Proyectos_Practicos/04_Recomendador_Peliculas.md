# ğŸ¬ Sistema de RecomendaciÃ³n de PelÃ­culas con Apache Spark

## ğŸ”¥ IntroducciÃ³n
Los **sistemas de recomendaciÃ³n** son una de las aplicaciones mÃ¡s populares en el campo de **Big Data** y **Machine Learning**. Apache **Spark MLlib** proporciona herramientas para construir un **motor de recomendaciÃ³n escalable y eficiente** basado en **filtrado colaborativo**.

---

## ğŸ“Œ Â¿QuÃ© es el Filtrado Colaborativo?
El **filtrado colaborativo** utiliza el comportamiento de los usuarios para recomendar productos similares. Se basa en dos enfoques principales:
1. **Basado en usuarios:** Encuentra usuarios con preferencias similares.
2. **Basado en Ã­tems:** Recomienda productos similares a los que el usuario ha calificado.

Spark utiliza el algoritmo **ALS (Alternating Least Squares)** para entrenar modelos de recomendaciÃ³n en grandes volÃºmenes de datos.

---

## ğŸ› ï¸ ImplementaciÃ³n en PySpark
### ğŸ”¹ 1. Inicializar SparkSession
```python
from pyspark.sql import SparkSession
from pyspark.ml.recommendation import ALS

spark = SparkSession.builder \
    .appName("RecomendadorPeliculas") \
    .getOrCreate()
```

---

### ğŸ”¹ 2. Cargar Datos de Calificaciones
```python
df = spark.read.csv("/ruta/dataset/ratings.csv", header=True, inferSchema=True)
df.show()
```
âœ… **Formato del dataset:**
```
+--------+---------+------+----------+
| userId | movieId | rating | timestamp |
+--------+---------+------+----------+
|    1   |   31    |  4.0  |  964982703|
|    2   |   102   |  5.0  |  964982224|
+--------+---------+------+----------+
```

---

### ğŸ”¹ 3. Entrenar el Modelo con ALS
```python
als = ALS(userCol="userId", itemCol="movieId", ratingCol="rating",
          coldStartStrategy="drop")
modelo = als.fit(df)
```
âœ… **Cold Start Strategy:** Evita problemas con datos no vistos en validaciÃ³n.

---

### ğŸ”¹ 4. Generar Recomendaciones para Usuarios
```python
recomendaciones = modelo.recommendForAllUsers(5)
recomendaciones.show(truncate=False)
```
âœ… **Salida esperada:**
```
+------+------------------------------------------------+
|userId|recommendations                                 |
+------+------------------------------------------------+
|   1  |[(50, 4.8), (34, 4.7), (78, 4.6), (2, 4.5), ...]|
+------+------------------------------------------------+
```

---

### ğŸ”¹ 5. Evaluar el Modelo
```python
from pyspark.ml.evaluation import RegressionEvaluator

evaluator = RegressionEvaluator(metricName="rmse", labelCol="rating", predictionCol="prediction")
predicciones = modelo.transform(df)
rmse = evaluator.evaluate(predicciones)
print(f"Error RMSE: {rmse}")
```
âœ… **RMSE (Root Mean Squared Error)** mide la precisiÃ³n del modelo.

---

## âš¡ OptimizaciÃ³n y Buenas PrÃ¡cticas
âœ… **Ajustar hiperparÃ¡metros:**
```python
als = ALS(rank=10, maxIter=20, regParam=0.1, userCol="userId", itemCol="movieId", ratingCol="rating")
```
âœ… **Filtrar datos con pocas calificaciones para evitar sesgos.**
âœ… **Utilizar particionamiento adecuado para distribuir la carga en el clÃºster.**

---

## ğŸ¯ ConclusiÃ³n
Apache **Spark MLlib** permite construir sistemas de recomendaciÃ³n escalables en grandes volÃºmenes de datos. Ajustando los hiperparÃ¡metros y aplicando optimizaciones adecuadas, se pueden obtener recomendaciones personalizadas con alta eficiencia. ğŸš€

